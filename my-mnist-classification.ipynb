{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MNIST Handwritten Digit Classification using Convolutional Neural Networks\n\nThis notebook demonstrates how to build a Convolutional Neural Network (CNN) to classify handwritten digits from the MNIST dataset. The MNIST dataset is a widely used benchmark in machine learning and consists of 28x28 grayscale images of handwritten digits (0-9).","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# For deep learning\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.utils import to_categorical\n\n# For model evaluation\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n\n# Set random seed for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Loading and Exploration\n\nWe'll load the MNIST dataset directly from Keras datasets.","metadata":{}},{"cell_type":"code","source":"# Load MNIST dataset\n(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the shape of the data\nprint(f\"X_train shape: {X_train.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\nprint(f\"X_test shape: {X_test.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display some sample images\nplt.figure(figsize=(10, 10))\nfor i in range(25):\n    plt.subplot(5, 5, i+1)\n    plt.imshow(X_train[i], cmap='gray')\n    plt.title(f\"Label: {y_train[i]}\")\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the distribution of digits in the training set\nplt.figure(figsize=(10, 6))\nsns.countplot(x=y_train)\nplt.title('Distribution of Digits in Training Set')\nplt.xlabel('Digit')\nplt.ylabel('Count')\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for missing values\nprint(f\"Missing values in X_train: {np.isnan(X_train).sum()}\")\nprint(f\"Missing values in y_train: {np.isnan(y_train).sum()}\")\nprint(f\"Missing values in X_test: {np.isnan(X_test).sum()}\")\nprint(f\"Missing values in y_test: {np.isnan(y_test).sum()}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the range of pixel values\nprint(f\"Min pixel value in X_train: {X_train.min()}\")\nprint(f\"Max pixel value in X_train: {X_train.max()}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Normalize the pixel values to be between 0 and 1\nX_train = X_train.astype('float32') / 255.0\nX_test = X_test.astype('float32') / 255.0","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Reshape the data to include the channel dimension (grayscale = 1 channel)\nX_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# One-hot encode the target variable\ny_train_encoded = to_categorical(y_train, 10)\ny_test_encoded = to_categorical(y_test, 10)\n\nprint(f\"Shape of y_train_encoded: {y_train_encoded.shape}\")\nprint(f\"Shape of y_test_encoded: {y_test_encoded.shape}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Building the CNN Model","metadata":{}},{"cell_type":"code","source":"# Define the CNN model architecture\nmodel = Sequential()\n\n# First Convolutional Block\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# Second Convolutional Block\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# Flatten and Dense Layers\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))  # 10 classes for digits 0-9","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model summary\nmodel.summary()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile the model\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define callbacks\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=10,\n    restore_best_weights=True\n)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.2,\n    patience=5,\n    min_lr=0.0001\n)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(\n    X_train, y_train_encoded,\n    epochs=20,\n    batch_size=128,\n    validation_split=0.1,\n    callbacks=[early_stopping, reduce_lr],\n    verbose=1\n)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{}},{"cell_type":"code","source":"# Plot training history\nplt.figure(figsize=(12, 5))\n\n# Plot training & validation accuracy values\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='lower right')\n\n# Plot training & validation loss values\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper right')\n\nplt.tight_layout()\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model on the test set\ntest_loss, test_accuracy = model.evaluate(X_test, y_test_encoded, verbose=0)\nprint(f\"Test Loss: {test_loss:.4f}\")\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Make predictions on the test set\ny_pred_proba = model.predict(X_test)\ny_pred = np.argmax(y_pred_proba, axis=1)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate confusion matrix\ncm = confusion_matrix(y_test, y_pred)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.title('Confusion Matrix')\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print classification report\nprint(classification_report(y_test, y_pred))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualizing Predictions","metadata":{}},{"cell_type":"code","source":"# Function to plot images with their predictions\ndef plot_predictions(X, true_labels, predicted_labels, num_images=25):\n    plt.figure(figsize=(12, 12))\n    for i in range(num_images):\n        plt.subplot(5, 5, i+1)\n        plt.imshow(X[i].reshape(28, 28), cmap='gray')\n        \n        # Green for correct predictions, red for incorrect\n        color = 'green' if true_labels[i] == predicted_labels[i] else 'red'\n        plt.title(f\"True: {true_labels[i]}\\nPred: {predicted_labels[i]}\", color=color)\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n\n# Plot some predictions\nplot_predictions(X_test, y_test, y_pred)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualizing Misclassifications","metadata":{}},{"cell_type":"code","source":"# Find misclassified examples\nmisclassified_indices = np.where(y_test != y_pred)[0]\nprint(f\"Number of misclassified examples: {len(misclassified_indices)}\")\n\n# Plot some misclassified examples\nif len(misclassified_indices) > 0:\n    num_to_plot = min(25, len(misclassified_indices))\n    misclassified_indices = misclassified_indices[:num_to_plot]\n    \n    plt.figure(figsize=(12, 12))\n    for i, idx in enumerate(misclassified_indices):\n        plt.subplot(5, 5, i+1)\n        plt.imshow(X_test[idx].reshape(28, 28), cmap='gray')\n        plt.title(f\"True: {y_test[idx]}\\nPred: {y_pred[idx]}\", color='red')\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feature Maps Visualization","metadata":{}},{"cell_type":"code","source":"# Create a model that outputs the feature maps from the first convolutional layer\nfeature_map_model = tf.keras.models.Model(\n    inputs=model.inputs,\n    outputs=model.layers[0].output\n)\n\n# Get feature maps for a sample image\nsample_image = X_test[0:1]  # Using the first test image\nfeature_maps = feature_map_model.predict(sample_image)\n\n# Plot the feature maps\nplt.figure(figsize=(15, 15))\nfor i in range(32):  # 32 filters in the first conv layer\n    plt.subplot(6, 6, i+1)\n    plt.imshow(feature_maps[0, :, :, i], cmap='viridis')\n    plt.axis('off')\nplt.tight_layout()\nplt.suptitle('Feature Maps of First Convolutional Layer', fontsize=16)\nplt.subplots_adjust(top=0.95)\nplt.show()\n\n# Display the original image for reference\nplt.figure(figsize=(5, 5))\nplt.imshow(X_test[0].reshape(28, 28), cmap='gray')\nplt.title(f\"Original Image (Digit: {y_test[0]})\")\nplt.axis('off')\nplt.show()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Making Predictions on New Data","metadata":{}},{"cell_type":"code","source":"# Function to preprocess and predict a single image\ndef predict_digit(image):\n    # Ensure the image is in the right format (28x28 grayscale)\n    if image.shape != (28, 28):\n        # Resize if needed\n        image = tf.image.resize(image, [28, 28])\n    \n    # Normalize and reshape\n    image = image.astype('float32') / 255.0\n    image = image.reshape(1, 28, 28, 1)\n    \n    # Make prediction\n    prediction = model.predict(image)\n    digit = np.argmax(prediction)\n    confidence = prediction[0][digit]\n    \n    return digit, confidence\n\n# Let's test this function on a sample from the test set\nsample_idx = 42  # Choose any index\nsample_image = X_test[sample_idx].reshape(28, 28)\n\n# Display the image\nplt.figure(figsize=(5, 5))\nplt.imshow(sample_image, cmap='gray')\nplt.title(f\"True Label: {y_test[sample_idx]}\")\nplt.axis('off')\nplt.show()\n\n# Make prediction\ndigit, confidence = predict_digit(sample_image)\nprint(f\"Predicted Digit: {digit}\")\nprint(f\"Confidence: {confidence:.4f} ({confidence*100:.2f}%)\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Conclusion\n\nIn this notebook, we built a Convolutional Neural Network (CNN) to classify handwritten digits from the MNIST dataset. The model achieved high accuracy on the test set, demonstrating the effectiveness of CNNs for image classification tasks.\n\nKey points from this project:\n\n1. CNNs are well-suited for image classification tasks due to their ability to learn spatial hierarchies of features.\n2. Data preprocessing, including normalization and reshaping, is crucial for good model performance.\n3. Techniques like batch normalization and dropout help prevent overfitting and improve model generalization.\n4. Visualizing predictions and misclassifications provides insights into the model's strengths and weaknesses.\n\nThis model could be further improved by:\n\n1. Using data augmentation to increase the training set size and diversity\n2. Implementing more sophisticated CNN architectures like ResNet or DenseNet\n3. Fine-tuning hyperparameters using techniques like grid search or Bayesian optimization\n4. Applying transfer learning from pre-trained models","metadata":{}},{"cell_type":"markdown","source":"## Saving the Model","metadata":{}},{"cell_type":"code","source":"# Save the model\nmodel.save('mnist_cnn_model.h5')\nprint(\"Model saved successfully!\")","metadata":{},"outputs":[],"execution_count":null}]}